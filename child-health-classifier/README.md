# ğŸ“˜ Child-Health Relevance Classification Pipeline  
### Machine-learning workflow for classifying bibliometric publications as *child-health relevant* or *not relevant*

This repository contains the full computational pipeline used to classify a large corpus of bibliometric publications into **child-health relevant** vs. **not relevant**, using manual annotations, text preprocessing, TF-IDF vectorization, and supervised machine learning (XGBoost).

---

## ğŸ§­ Overview

The workflow:

1. Processes bibliometric text (titles, abstracts, metadata)  
2. Builds abbreviation dictionaries  
3. Cleans and tokenizes text  
4. Trains a supervised classifier using human-labeled publications  
5. Predicts relevance for the full publication   

All steps are scripted and reproducible.

---

# ğŸ“‚ Project Structure

```
project/
â”œâ”€â”€ README.md
â”œâ”€â”€ scripts/
â”‚   â”œâ”€â”€ make_abbreviation_dicts.py
â”‚   â”œâ”€â”€ make_processed_text.py
â”‚   â”œâ”€â”€ train_model.py
â”‚   â”œâ”€â”€ train_model_hyperparam.py
â”‚   â””â”€â”€ predict_labels.py
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ raw/              # User-supplied Scopus data (NOT included)
â”‚   â”œâ”€â”€ interim/          # Abbreviation dictionaries (generated)
â”‚   â””â”€â”€ processed/        # Tokenized text + predictions (generated)
â”œâ”€â”€ models/
â”‚   â”œâ”€â”€ model_output/     # Metrics, ROC, confusion matrix (generated)
â”‚   â””â”€â”€ *.pkl             # Trained XGBoost model(s) (generated)
â””â”€â”€ Makefile
```

---

# ğŸ“¢ Data Availability & Scopus Licensing Restrictions

âš ï¸ **Important notice**

The raw publication metadata used in this pipeline (titles, abstracts, journals, subject areas) were retrieved from **Elsevierâ€™s Scopus API**.

Under **Scopus data-sharing conditions**, researchers **cannot redistribute**:

- full abstracts  
- full titles  
- journal metadata  
- subject areas  

Therefore, this repository **does not include** any files containing Scopus-restricted metadata.

### What **cannot** be shared
âŒ `data/raw/Pubs_df.csv`  
âŒ `data/raw/Pubs_labeled.csv`  
âŒ Any raw metadata from Scopus

If you wish to reproduce the workflow, you must **retrieve the raw metadata yourself** using Scopus

---

# ğŸ“¦ Data Description

### **`data/raw/`**  
*(Not included â€” must be created by the user)*

This directory should contain two Scopus-derived CSVs:

- **`Pubs_labeled.csv`**  
  Human-annotated publications with binary relevance labels  
  (`1 = child-health relevant`, `0 = not relevant`)  

- **`Pubs_df.csv`**  
  Publication metadata (title, abstract, journal, etc.)  
  Must be retrieved by the user via Scopus.

---

### **`data/interim/`**  
*(Generated automatically)*

- `abbreviation_dicts_abs.json`
  Detected abbreviations extracted directly from the abstracts during preprocessing.
- `updated_abbreviation_dicts_abs.json`
A refined version of the abbreviation dictionary where abbreviation variants referring to the same concept have been unified.

Stores abbreviation detection output and cleaned mappings.

---

### **`data/processed/`**  
*(Generated automatically)*

- `Pubs_processed_tokens.csv`  
  Tokenized and normalized text 
- `Pubs_with_predictions.csv`  
  Classifier predictions + probabilities
  
---

### **`models/`**  
*(Generated after running training scripts)*

This directory is created when you run the model training scripts.

It contains:

- **`child_health_xgb_pipeline.pkl`**  
  TF-IDF + XGBoost trained pipeline  
- **`model_output/`**  
  Evaluation results:
  - ROC curve  
  - Confusion matrix  
  - Precision/Recall/F1  
  - Classification report  

---

# ğŸ”§ Pipeline Components

## **1. Abbreviation dictionary construction**  
**`scripts/make_abbreviation_dicts.py`**

- Detects abbreviations in abstracts  
- Builds and saves JSON dictionaries  

Outputs:

- `abbreviation_dicts_abs.json`  
- `updated_abbreviation_dicts_abs.json`  (applied some unifying abbrevaition for some expression that are same but abbreviated differenlty in differnet abstract on the abbreviation_dicts_abs) 

---

## **2. Text processing & tokenization**  
**`scripts/make_processed_text.py`**

- Expands abbreviations  
- Normalizes text  
- Tokenizes titles & abstracts  
- Generates fields used for TF-IDF

Output:

- `data/processed/Pubs_processed_tokens.csv`

---

## **3. Train the classifier**

### A. **Default model**
**`scripts/train_model.py`**

Performs:

- TF-IDF vectorization  
- Train/test split  
- XGBoost training  
- Metrics generation

### B. **Hyperparameter tuning (optional)**  
**`scripts/train_model_hyperparam.py`**

- RandomizedSearchCV (100 sampled configurations)  
- Saves best-performing model

Outputs:

- Trained model `.pkl`  
- Metrics in `models/model_output/`

---

## **4. Predict relevance**
**`scripts/predict_labels.py`**

- Loads trained model  
- Predicts relevance for full corpus  
- Saves predictions as CSV

Output:

- `data/processed/Pubs_with_predictions.csv`

---

# ğŸš€ Running the Pipeline

## **Option 1 â€” Use the Makefile **

```bash
make
```

Runs all steps in sequence.

Run individual components:

```bash
make abbrev
make process
make train
make train_hyper
make predict
```

---

## **Option 2 â€” Run scripts manually**


---

# ğŸ“Š Model Description

- **Model:** XGBoost (binary classifier)  
- **Features:** TF-IDF vectors from processed title + abstract tokens  
- **Labels:** Human-annotated relevance labels  
- **Metrics:**  
  - Accuracy  
  - Precision  
  - Recall  
  - F1  
  - Confusion matrix  

---

# ğŸ“¬ Contact

**Masoumeh Dehghani**  
Data Analyst, Alberta Childrenâ€™s Hospital Research Institute (ACHRI)  
University of Calgary  
ğŸ“§ masoumeh.dehghanimog@ucalgary.ca | dm.dehghani@gmail.com
